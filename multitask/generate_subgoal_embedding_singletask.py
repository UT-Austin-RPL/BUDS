import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import h5py
import numpy as np
import cv2
import os

import argparse
import init_path
from models.model_utils import safe_cuda
from models.conf_utils import *
from models.torch_utils import *
from goal_skill_learning.models import *
from goal_skill_learning.datasets import *
from goal_skill_learning.hydra_path_templates import *

def get_subtask_label(idx, saved_ep_subtasks_seq, horizon):
    for (start_idx, end_idx, subtask_label) in saved_ep_subtasks_seq:
        if start_idx <= idx <= end_idx:
            return min(end_idx, idx + horizon), subtask_label

import hydra
from omegaconf import OmegaConf, DictConfig
import yaml
from easydict import EasyDict
from hydra.experimental import compose, initialize

@hydra.main(config_path="../conf", config_name="config")
def main(hydra_cfg):
    # args = get_common_args(training=True)
    # cfg = update_json_config(args)

    yaml_config = OmegaConf.to_yaml(hydra_cfg, resolve=True)
    cfg = EasyDict(yaml.load(yaml_config))
    
    folder_path = "./"
    
    modalities = cfg.repr.modalities    
    modality_str = get_modalities_str(cfg)
    goal_str = get_goal_str(cfg)

    out_parent_dir = f"datasets/{cfg.data.dataset_name}"

    demo_file_name = os.path.join(out_parent_dir, "demo.hdf5")
    demo_file = h5py.File(demo_file_name, "r")
    num_eps = demo_file["data"].attrs["num_eps"]

    action_dim = len(demo_file["data/ep_0/actions"][()][0])

    proprio_dim = 0
    if cfg.skill_training.use_gripper:
        proprio_dim += len(demo_file["data/ep_0/gripper_states"][()][0]) * 5
    if cfg.skill_training.use_joints:
        proprio_dim += len(demo_file["data/ep_0/joint_states"][()][0])

    if cfg.multitask.training_task_id == -1:
        subtask_file_name = folder_path+f"results/skill_data/{cfg.data.dataset_name}_subtasks_{modality_str}_{cfg.repr.z_dim}_{cfg.agglomoration.footprint}_{cfg.agglomoration.dist}_{cfg.agglomoration.segment_footprint}_K{cfg.skill_training.agglomoration.K}_{cfg.agglomoration.affinity}.hdf5"
    else:
        subtask_file_name = folder_path+f"results/skill_data/{cfg.data.dataset_name}_SingleTask_{cfg.multitask.training_task_id}_subtasks_{modality_str}_{cfg.repr.z_dim}_{cfg.agglomoration.footprint}_{cfg.agglomoration.dist}_{cfg.agglomoration.segment_footprint}_K{cfg.skill_training.agglomoration.K}_{cfg.agglomoration.affinity}.hdf5"        
    subtask_file = h5py.File(subtask_file_name, "r")
    num_subtask = subtask_file["subtasks"].attrs["num_subtasks"]

    subgoal_embedding_file_name = singletask_subgoal_embedding_path_template(cfg, modality_str)
        
    subgoal_embedding_file = h5py.File(subgoal_embedding_file_name, "w")

    networks = {}
    if cfg.skill_subgoal_cfg is not None:
        subgoal_visual_feature_dimension = cfg.skill_subgoal_cfg.visual_feature_dimension
    else:
        raise ValueError

    if cfg.skill_training.policy_type == "no_subgoal":
        policy_type = PolicyType.NO_SUBGOAL
    elif cfg.skill_training.policy_type == "normal_subgoal":
        policy_type = PolicyType.NORMAL_SUBGOAL
    if cfg.skill_training.policy_type == "normal_subgoal":
        for i in range(num_subtask):
            template = single_subskill_path_template(cfg, subtask_id=i, use_cvae=cfg.skill_cvae_cfg.enable)
            output_dir = template.output_dir
            model_checkpoint_name = template.model_checkpoint_name
            network_state_dict, network_cfg = torch_load_model(model_checkpoint_name)

            print(model_checkpoint_name)
            # print(network_cfg)

            if cfg.skill_cvae_cfg.enable:
                network = safe_cuda(BCVAEPolicy(action_dim=action_dim,
                                               state_dim=network_cfg.skill_training.state_dim,
                                               proprio_dim=proprio_dim,
                                               data_modality=network_cfg.skill_training.data_modality,
                                               use_eye_in_hand=network_cfg.skill_training.use_eye_in_hand,
                                               use_subgoal_eye_in_hand=network_cfg.skill_subgoal_cfg.use_eye_in_hand,
                                               activation=network_cfg.skill_training.activation,
                                               z_dim=network_cfg.repr.z_dim,
                                               num_kp=network_cfg.skill_training.num_kp,
                                               img_h=network_cfg.skill_training.img_h,
                                               img_w=network_cfg.skill_training.img_w,
                                               visual_feature_dimension=network_cfg.skill_training.visual_feature_dimension,
                                               subgoal_visual_feature_dimension=subgoal_visual_feature_dimension,
                                               action_squash=network_cfg.skill_training.action_squash,
                                               policy_layer_dims=network_cfg.skill_training.policy_layer_dims,
                                               policy_type=policy_type,
                                               subgoal_type=network_cfg.skill_subgoal_cfg.subgoal_type,
                                               latent_dim=network_cfg.skill_cvae_cfg.latent_dim,
                ))
            elif cfg.skill_training.use_rnn:
                print("Using BC RNN")
                network = safe_cuda(BCRNNPolicy(action_dim=action_dim,
                                                  proprio_dim=proprio_dim,
                                                  data_modality=network_cfg.skill_training.data_modality,
                                                  use_eye_in_hand=network_cfg.skill_training.use_eye_in_hand,
                                                  use_subgoal_eye_in_hand=network_cfg.skill_subgoal_cfg.use_eye_in_hand,
                                                  activation=network_cfg.skill_training.activation,
                                                  z_dim=network_cfg.repr.z_dim,
                                                  num_kp=network_cfg.skill_training.num_kp,
                                                  img_h=network_cfg.skill_training.img_h,
                                                  img_w=network_cfg.skill_training.img_w,
                                                  visual_feature_dimension=network_cfg.skill_training.visual_feature_dimension,
                                                  subgoal_visual_feature_dimension=subgoal_visual_feature_dimension,
                                                  action_squash=network_cfg.skill_training.action_squash,                                  
                                                  policy_layer_dims=network_cfg.skill_training.policy_layer_dims,
                                                  policy_type=policy_type,
                                                  subgoal_type=network_cfg.skill_subgoal_cfg.subgoal_type,
                                                  rnn_num_layers=network_cfg.skill_training.rnn_num_layers,
                                                  rnn_hidden_dim=network_cfg.skill_training.rnn_hidden_dim,
                                                  rnn_horizon=network_cfg.skill_subgoal_cfg.horizon))
                
            else:
                network = safe_cuda(BCPolicy(action_dim=action_dim,
                                            state_dim=network_cfg.skill_training.state_dim,
                                            proprio_dim=proprio_dim,
                                            data_modality=network_cfg.skill_training.data_modality,
                                            use_eye_in_hand=network_cfg.skill_training.use_eye_in_hand,
                                            use_subgoal_eye_in_hand=network_cfg.skill_subgoal_cfg.use_eye_in_hand,
                                           use_subgoal_spatial_softmax=network_cfg.skill_subgoal_cfg.use_spatial_softmax,                                            
                                            activation=network_cfg.skill_training.activation,
                                            z_dim=network_cfg.repr.z_dim,
                                            num_kp=network_cfg.skill_training.num_kp,
                                            img_h=network_cfg.skill_training.img_h,
                                            img_w=network_cfg.skill_training.img_w,
                                            visual_feature_dimension=network_cfg.skill_training.visual_feature_dimension,
                                            subgoal_visual_feature_dimension=subgoal_visual_feature_dimension,
                                            action_squash=network_cfg.skill_training.action_squash,
                                            policy_layer_dims=network_cfg.skill_training.policy_layer_dims,
                                            policy_type=policy_type,
                                            subgoal_type=cfg.skill_subgoal_cfg.subgoal_type))
            network.load_state_dict(network_state_dict)
            networks[i] = network

    grp = subgoal_embedding_file.create_group("data")
    for ep_idx in range(num_eps):
        # Generate embedding
        if f"ep_subtasks_seq_{ep_idx}" not in subtask_file["subtasks"]:
            print(f"Skipping {ep_idx}")
            continue
        saved_ep_subtasks_seq = subtask_file["subtasks"][f"ep_subtasks_seq_{ep_idx}"][()]
        agentview_image_names = demo_file[f"data/ep_{ep_idx}/agentview_image_names"][()]
        eye_in_hand_image_names = demo_file[f"data/ep_{ep_idx}/eye_in_hand_image_names"][()]

        embeddings = []
        print("Ep: ", ep_idx)
        for i in range(len(agentview_image_names)):
            future_idx, subtask_label = get_subtask_label(i, saved_ep_subtasks_seq, horizon=cfg.skill_subgoal_cfg.horizon)
            agentview_image = safe_cuda(torch.from_numpy(np.array(Image.open(agentview_image_names[future_idx])).transpose(2, 0, 1)).unsqueeze(0)).float() / 255.
            eye_in_hand_image = safe_cuda(torch.from_numpy(np.array(Image.open(eye_in_hand_image_names[future_idx])).transpose(2, 0, 1)).unsqueeze(0)).float() / 255.

            if network_cfg.skill_subgoal_cfg.use_eye_in_hand:
                state_image = torch.cat([agentview_image, eye_in_hand_image], dim=1)
            else:
                state_image = agentview_image
            embedding = networks[subtask_label].get_embedding(state_image).detach().cpu().numpy().squeeze()
            embeddings.append(embedding)

        if ep_idx % 10 == 0:
            for (start_idx, end_idx, subtask_label) in saved_ep_subtasks_seq:
                print(f"Subtask: {subtask_label}")
                print(np.round(embeddings[start_idx], 2))
                print(np.round(embeddings[end_idx], 2))
            
        ep_data_grp = grp.create_group(f"ep_{ep_idx}")
        ep_data_grp.create_dataset("embedding", data=np.stack(embeddings, axis=0))

    grp.attrs["embedding_dim"] = len(embeddings[-1])
    subtask_file.close()
    demo_file.close()
    subgoal_embedding_file.close()
    

if __name__ == "__main__":
    main()
